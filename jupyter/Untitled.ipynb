{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8f505824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import PIL.Image as Image\n",
    "import os\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import zipfile\n",
    "\n",
    "import cv2 as cv\n",
    "from IPython.display import clear_output as cls\n",
    "\n",
    "# Data \n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "# Data Visuaalization\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "# Model\n",
    "from tensorflow.keras.models import load_model\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "551ad965",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('archive.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debb1d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2225275f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3a746d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a2c46a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a random\n",
    "np.random.seed(42)\n",
    "# Define the image dimensions\n",
    "IMG_W, IMG_H, IMG_C = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3ed31eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Persons: 105\n",
      "\n",
      "Name of the Persons : \n",
      "\t['Adriana Lima', 'Alex Lawther', 'Alexandra Daddario', 'Alvaro Morte', 'Alycia Dabnem Carey', 'Amanda Crew', 'Amber Heard', 'Andy Samberg', 'Anne Hathaway', 'Anthony Mackie', 'Avril Lavigne', 'Barack Obama', 'Barbara Palvin', 'Ben Affleck', 'Bill Gates', 'Bobby Morley', 'Brenton Thwaites', 'Brian J. Smith', 'Brie Larson', 'Camila Mendes', 'Chris Evans', 'Chris Hemsworth', 'Chris Pratt', 'Christian Bale', 'Cristiano Ronaldo', 'Danielle Panabaker', 'Dominic Purcell', 'Dwayne Johnson', 'Eliza Taylor', 'Elizabeth Lail', 'Elizabeth Olsen', 'Ellen Page', 'Elon Musk', 'Emilia Clarke', 'Emma Stone', 'Emma Watson', 'Gal Gadot', 'Grant Gustin', 'Gwyneth Paltrow', 'Henry Cavil', 'Hugh Jackman', 'Inbar Lavi', 'Irina Shayk', 'Jake Mcdorman', 'Jason Momoa', 'Jeff Bezos', 'Jennifer Lawrence', 'Jeremy Renner', 'Jessica Barden', 'Jimmy Fallon', 'Johnny Depp', 'Josh Radnor', 'Katharine Mcphee', 'Katherine Langford', 'Keanu Reeves', 'Kiernen Shipka', 'Krysten Ritter', 'Leonardo Dicaprio', 'Lili Reinhart', 'Lindsey Morgan', 'Lionel Messi', 'Logan Lerman', 'Madelaine Petsch', 'Maisie Williams', 'Margot Robbie', 'Maria Pedraza', 'Marie Avgeropoulos', 'Mark Ruffalo', 'Mark Zuckerberg', 'Megan Fox', 'Melissa Fumero', 'Miley Cyrus', 'Millie Bobby Brown', 'Morena Baccarin', 'Morgan Freeman', 'Nadia Hilker', 'Natalie Dormer', 'Natalie Portman', 'Neil Patrick Harris', 'Pedro Alonso', 'Penn Badgley', 'Rami Malek', 'Rebecca Ferguson', 'Richard Harmon', 'Rihanna', 'Robert De Niro', 'Robert Downey Jr', 'Sarah Wayne Callies', 'Scarlett Johansson', 'Selena Gomez', 'Shakira Isabel Mebarak', 'Sophie Turner', 'Stephen Amell', 'Taylor Swift', 'Tom Cruise', 'Tom Ellis', 'Tom Hardy', 'Tom Hiddleston', 'Tom Holland', 'Tuppence Middleton', 'Ursula Corbero', 'Wentworth Miller', 'Zac Efron', 'Zendaya', 'Zoe Saldana']\n"
     ]
    }
   ],
   "source": [
    "# Specify the root directory path\n",
    "root_path = '105_classes_pins_dataset/'\n",
    "# Collect all the person names\n",
    "dir_names = os.listdir(root_path)\n",
    "person_names = [name.split(\"_\")[-1].title() for name in dir_names]\n",
    "n_individuals = len(person_names)\n",
    "print(f\"Total number of Persons: {n_individuals}\\n\")\n",
    "print(f\"Name of the Persons : \\n\\t{person_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "19802bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Images : 17534.\n"
     ]
    }
   ],
   "source": [
    "# Number of images available per person\n",
    "n_images_per_person = [len(os.listdir(root_path + name)) for name in dir_names]\n",
    "n_images = sum(n_images_per_person)\n",
    "\n",
    "# Show\n",
    "print(f\"Total Number of Images : {n_images}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3353f6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(10)\n",
    "test_size = len(root_path)//5\n",
    "train_size = len(root_path) - test_size\n",
    "\n",
    "train_ds, test_ds = random_split(root_path, [train_size, test_size])\n",
    "len(train_ds), len(test_ds)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89774f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(x=person_names, y=n_images_per_person, color=person_names)\n",
    "fig.update_layout({'title':{'text':\"Distribution of images per person\"}})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcf3cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all the file paths : 10 images per person.\n",
    "filepaths = [path  for name in dir_names for path in glob(root_path + name + '/*')[:10]]\n",
    "np.random.shuffle(filepaths)\n",
    "print(f\"Total number of images to be loaded : {len(filepaths)}\")\n",
    "\n",
    "# Create space for the images\n",
    "all_images = np.empty(shape=(len(filepaths), IMG_W, IMG_H, IMG_C), dtype = np.float32)\n",
    "all_labels = np.empty(shape=(len(filepaths), 1), dtype = np.int32)\n",
    "\n",
    "# For each path, load the image and apply some preprocessing.\n",
    "for index, path in tqdm(enumerate(filepaths), desc=\"Loading Data\"):\n",
    "    \n",
    "    # Extract label\n",
    "    label = [name[5:] for name in dir_names if name in path][0]\n",
    "    label = person_names.index(label.title())\n",
    "    \n",
    "    # Load the Image\n",
    "    image = plt.imread(path)\n",
    "        # Resize the image\n",
    "    image = cv.resize(image, dsize = (IMG_W, IMG_H))\n",
    "    \n",
    "    # Convert image stype\n",
    "    image = image.astype(np.float32)/255.0\n",
    "    \n",
    "    # Store the image and the label\n",
    "    all_images[index] = image\n",
    "    all_labels[index] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826102bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(\n",
    "    images: np.ndarray, \n",
    "    labels: np.ndarray,\n",
    "    GRID: tuple=(15,6),\n",
    "    FIGSIZE: tuple=(25,50), \n",
    "    recog_fn = None,\n",
    "    database = None\n",
    ") -> None:\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to plot a grid of images with their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        images (numpy.ndarray): Array of images to plot.\n",
    "        labels (numpy.ndarray): Array of corresponding labels for each image.\n",
    "        GRID (tuple, optional): Tuple with the number of rows and columns of the plot grid. Defaults to (15,6).\n",
    "        FIGSIZE (tuple, optional): Tuple with the size of the plot figure. Defaults to (30,50).\n",
    "        recog_fn (function, optional): Function to perform face recognition. Defaults to None.\n",
    "        database (dictionary, optional): Dictionary with the encoding of the images for face recognition. Defaults to None.\n",
    "\n",
    "Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Plotting Configuration\n",
    "    plt.figure(figsize=FIGSIZE)\n",
    "    n_rows, n_cols = GRID\n",
    "    n_images = n_rows * n_cols\n",
    "    \n",
    "    # loop over the images and labels\n",
    "    for index in range(n_images):\n",
    "        \n",
    "        # Select image in the corresponding label randomly\n",
    "        image_index = np.random.randint(len(images))\n",
    "        image, label = images[image_index], person_names[int(labels[image_index])]\n",
    "        \n",
    "        # Create a Subplot\n",
    "        plt.subplot(n_rows, n_cols, index+1)\n",
    "        \n",
    "        # Plot Image\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        if recog_fn is None:\n",
    "            # Plot title\n",
    "            plt.title(label)\n",
    "        else:\n",
    "            recognized = recog_fn(image, database)\n",
    "            plt.title(f\"True:{label}\\nPred:{recognized}\")\n",
    "    \n",
    "    # Show final Plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f193e339",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data(images = all_images, labels = all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47b074b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d6ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc938019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a25610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names0=dataset.classes\n",
    "class_names=[]\n",
    "for name in class_names0:\n",
    "    class_names+=[name[5:]]\n",
    "print(class_names)\n",
    "print(len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3984811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder exists\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the extracted folder\n",
    "path_to_folder = \"archive.zip\"\n",
    "\n",
    "# Check if the folder exists\n",
    "if os.path.exists(path_to_folder):\n",
    "    print(\"The folder exists\")\n",
    "else:\n",
    "    print(\"The folder does not exist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa297864",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[WinError 267] The directory name is invalid: 'archive.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m path_to_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marchive.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Get a list of all files and directories in the directory\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m files_and_directories \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Filter the directories from the list\u001b[39;00m\n\u001b[0;32m      8\u001b[0m directories \u001b[38;5;241m=\u001b[39m [d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m files_and_directories \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path_to_directory, d))]\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m: [WinError 267] The directory name is invalid: 'archive.zip'"
     ]
    }
   ],
   "source": [
    "# Set the path to the directory\n",
    "path_to_directory = \"archive.zip\"\n",
    "\n",
    "# Get a list of all files and directories in the directory\n",
    "files_and_directories = os.listdir(path_to_directory)\n",
    "\n",
    "# Filter the directories from the list\n",
    "directories = [d for d in files_and_directories if os.path.isdir(os.path.join(path_to_directory, d))]\n",
    "\n",
    "# Print the list of directory names\n",
    "print(directories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78621da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('datasets/archive.zip')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testloader = torch.utils.data.DataLoader(X_test, y_test, batch_size=64, shuffle=True)\n",
    "# Iterate over the batches and scale the data\n",
    "for data in testloader:\n",
    "    X_test_scaled = data / 255.0  # scale the images\n",
    "    y_test_scaled\n",
    "    labels = None  # there are no labels in this DataLoader, as it's just a set of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ff2f0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert X_train and y_train to tensors\n",
    "X_train = torch.tensor(X_train)\n",
    "y_train = torch.tensor(y_train)\n",
    "\n",
    "# Create a TensorDataset object\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "\n",
    "# Create a DataLoader object\n",
    "trainloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "# Iterate over the batches and scale the data\n",
    "for data in trainloader:\n",
    "    X_train_scaled = data[0] / 255.0\n",
    "    labels = data[1]\n",
    "    # Do something with the scaled data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6033ed94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the input shape\n",
    "input_shape = (img_height, img_width, 3)\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  Conv2D(16, 3, padding='same', activation='relu', input_shape=input_shape),\n",
    "  MaxPooling2D(),\n",
    "  Dropout(0.2),\n",
    "  Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  MaxPooling2D(),\n",
    "  Dropout(0.2),\n",
    "  Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  MaxPooling2D(),\n",
    "  Dropout(0.2),\n",
    "  Flatten(),\n",
    "  Dense(128, activation='relu'),\n",
    "  Dense(num_classes)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Set up early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs,\n",
    "  callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(X_test_np, y_test_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebfa10c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4687fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5616ab89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c141311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d947ad4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m IMAGE_SHAPE \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m classifier \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m      4\u001b[0m     hub\u001b[38;5;241m.\u001b[39mKerasLayer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39mIMAGE_SHAPE\u001b[38;5;241m+\u001b[39m(\u001b[38;5;241m3\u001b[39m,))\n\u001b[0;32m      5\u001b[0m ])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "IMAGE_SHAPE = (224, 224)\n",
    "\n",
    "classifier = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\", input_shape=IMAGE_SHAPE+(3,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e5519",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
